{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "2300/2300 [==============================] - 13s 4ms/step - loss: 0.0530 - mae: 0.1548 - val_loss: 0.0427 - val_mae: 0.1349\n",
      "Epoch 2/25\n",
      "2300/2300 [==============================] - 10s 4ms/step - loss: 0.0439 - mae: 0.1382 - val_loss: 0.0404 - val_mae: 0.1292\n",
      "Epoch 3/25\n",
      "2300/2300 [==============================] - 10s 4ms/step - loss: 0.0414 - mae: 0.1320 - val_loss: 0.0382 - val_mae: 0.1230\n",
      "Epoch 4/25\n",
      "2300/2300 [==============================] - 11s 5ms/step - loss: 0.0389 - mae: 0.1248 - val_loss: 0.0374 - val_mae: 0.1200\n",
      "Epoch 5/25\n",
      "2300/2300 [==============================] - 11s 5ms/step - loss: 0.0382 - mae: 0.1224 - val_loss: 0.0375 - val_mae: 0.1182\n",
      "Epoch 6/25\n",
      "2300/2300 [==============================] - 10s 4ms/step - loss: 0.0379 - mae: 0.1212 - val_loss: 0.0369 - val_mae: 0.1186\n",
      "Epoch 7/25\n",
      "2300/2300 [==============================] - 10s 4ms/step - loss: 0.0377 - mae: 0.1206 - val_loss: 0.0369 - val_mae: 0.1186\n",
      "Epoch 8/25\n",
      "2300/2300 [==============================] - 10s 5ms/step - loss: 0.0376 - mae: 0.1203 - val_loss: 0.0367 - val_mae: 0.1172\n",
      "Epoch 9/25\n",
      "2300/2300 [==============================] - 10s 4ms/step - loss: 0.0375 - mae: 0.1200 - val_loss: 0.0367 - val_mae: 0.1166\n",
      "Epoch 10/25\n",
      "2300/2300 [==============================] - 10s 4ms/step - loss: 0.0374 - mae: 0.1196 - val_loss: 0.0367 - val_mae: 0.1172\n",
      "Epoch 11/25\n",
      "2300/2300 [==============================] - 10s 4ms/step - loss: 0.0373 - mae: 0.1194 - val_loss: 0.0365 - val_mae: 0.1176\n",
      "Epoch 12/25\n",
      "2300/2300 [==============================] - 10s 4ms/step - loss: 0.0373 - mae: 0.1194 - val_loss: 0.0365 - val_mae: 0.1177\n",
      "Epoch 13/25\n",
      "2300/2300 [==============================] - 10s 4ms/step - loss: 0.0372 - mae: 0.1192 - val_loss: 0.0364 - val_mae: 0.1172\n",
      "Epoch 14/25\n",
      "2300/2300 [==============================] - 10s 4ms/step - loss: 0.0371 - mae: 0.1190 - val_loss: 0.0364 - val_mae: 0.1164\n",
      "Epoch 15/25\n",
      "2300/2300 [==============================] - 10s 5ms/step - loss: 0.0371 - mae: 0.1189 - val_loss: 0.0366 - val_mae: 0.1182\n",
      "Epoch 16/25\n",
      "2300/2300 [==============================] - 10s 5ms/step - loss: 0.0371 - mae: 0.1189 - val_loss: 0.0363 - val_mae: 0.1169\n",
      "Epoch 17/25\n",
      "2300/2300 [==============================] - 10s 4ms/step - loss: 0.0371 - mae: 0.1188 - val_loss: 0.0363 - val_mae: 0.1172\n",
      "Epoch 18/25\n",
      "2300/2300 [==============================] - 10s 4ms/step - loss: 0.0370 - mae: 0.1187 - val_loss: 0.0363 - val_mae: 0.1160\n",
      "Epoch 19/25\n",
      "2300/2300 [==============================] - 10s 4ms/step - loss: 0.0370 - mae: 0.1185 - val_loss: 0.0364 - val_mae: 0.1166\n",
      "Epoch 20/25\n",
      "2300/2300 [==============================] - 10s 4ms/step - loss: 0.0370 - mae: 0.1186 - val_loss: 0.0363 - val_mae: 0.1171\n",
      "Epoch 21/25\n",
      "2300/2300 [==============================] - 10s 4ms/step - loss: 0.0370 - mae: 0.1185 - val_loss: 0.0363 - val_mae: 0.1167\n",
      "Epoch 22/25\n",
      "2300/2300 [==============================] - 10s 4ms/step - loss: 0.0370 - mae: 0.1184 - val_loss: 0.0364 - val_mae: 0.1175\n",
      "Epoch 23/25\n",
      "2300/2300 [==============================] - 10s 4ms/step - loss: 0.0369 - mae: 0.1184 - val_loss: 0.0362 - val_mae: 0.1169\n",
      "Epoch 24/25\n",
      "2300/2300 [==============================] - 10s 4ms/step - loss: 0.0369 - mae: 0.1183 - val_loss: 0.0363 - val_mae: 0.1176\n",
      "Epoch 25/25\n",
      "2300/2300 [==============================] - 10s 4ms/step - loss: 0.0369 - mae: 0.1183 - val_loss: 0.0364 - val_mae: 0.1174\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Charu Gupta\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\engine\\training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "import datetime\n",
    "import joblib\n",
    "\n",
    "# Load the dataset\n",
    "dataset = pd.read_csv('new_dataset.csv')  # Replace with your dataset's path\n",
    "\n",
    "# Extract features and targets\n",
    "dataset['valid_time'] = pd.to_datetime(dataset['valid_time'])\n",
    "dataset['day_of_year'] = dataset['valid_time'].dt.dayofyear\n",
    "dataset['hour'] = dataset['valid_time'].dt.hour\n",
    "processed_data = dataset.drop(columns=['valid_time', 'number', 'expver'])\n",
    "\n",
    "X = processed_data[['day_of_year', 'hour']].values\n",
    "y = processed_data.drop(columns=['day_of_year', 'hour']).values\n",
    "\n",
    "# Normalize the input features (X) and target values (y)\n",
    "scaler_X = MinMaxScaler()\n",
    "X_scaled = scaler_X.fit_transform(X)\n",
    "\n",
    "scaler_y = MinMaxScaler()\n",
    "y_scaled = scaler_y.fit_transform(y)\n",
    "\n",
    "# Save the scalers \n",
    "joblib.dump(scaler_X, \"scaler_X.pkl\")\n",
    "joblib.dump(scaler_y, \"scaler_y.pkl\")\n",
    "\n",
    "# Reshape X_scaled to a 3D array (samples, timesteps, features)\n",
    "X_scaled = np.expand_dims(X_scaled, axis=1) \n",
    "\n",
    "# Split the dataset into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_scaled, y_scaled, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define the LSTM model\n",
    "model = Sequential([\n",
    "    LSTM(128, activation='relu', input_shape=(X_scaled.shape[1], X_scaled.shape[2]), return_sequences=True),\n",
    "    Dropout(0.2),\n",
    "    LSTM(64, activation='relu', return_sequences=False),\n",
    "    Dropout(0.2),\n",
    "    Dense(y_scaled.shape[1])  \n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs=25,\n",
    "    batch_size=32,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Save the trained model\n",
    "model_file_path = 'lstm_model.h5'\n",
    "model.save(model_file_path)\n",
    "\n",
    "\n",
    "# Define the prediction function\n",
    "def predict_for_date(date_string, hour):\n",
    "    # Convert date string to day_of_year\n",
    "    input_date = datetime.datetime.strptime(date_string, \"%Y-%m-%d\")\n",
    "    day_of_year = input_date.timetuple().tm_yday\n",
    "    input_features = np.array([[day_of_year, hour]])  # Create a 2D array for input features\n",
    "\n",
    "    # Normalize the input features using scaler_X\n",
    "    input_features_scaled = scaler_X.transform(input_features)\n",
    "\n",
    "    # Reshape to match LSTM input shape (samples, timesteps, features)\n",
    "    input_features_scaled = np.expand_dims(input_features_scaled, axis=1)  # Add timestep dimension\n",
    "\n",
    "    # Make predictions\n",
    "    predictions_scaled = model.predict(input_features_scaled)\n",
    "\n",
    "    # Rescale predictions back to the original range using scaler_y\n",
    "    predictions_rescaled = scaler_y.inverse_transform(predictions_scaled)\n",
    "\n",
    "    return predictions_rescaled[0]  # Return as a flat array\n",
    "\n",
    "\n",
    "# Define the function to interpret climatic conditions\n",
    "def interpret_climatic_conditions(predictions, columns):\n",
    "    conditions = []\n",
    "    predicted_values = dict(zip(columns, predictions))\n",
    "\n",
    "    # Interpret temperature (convert from Kelvin to Celsius)\n",
    "    temp = predicted_values.get(\"t2m\", 0) - 273.15  # Convert Kelvin to Celsius\n",
    "    if temp > 35:\n",
    "        conditions.append(\"Heatwave warning\")\n",
    "    elif 0 <= temp <= 35:\n",
    "        conditions.append(\"Normal temperature\")\n",
    "    elif temp < 0:\n",
    "        conditions.append(\"Frost warning\")\n",
    "\n",
    "    # Interpret precipitation\n",
    "    precip = predicted_values.get(\"tp\", 0)  # Replace \"tp\" with actual precipitation column name\n",
    "    if precip > 50:\n",
    "        conditions.append(\"Heavy rainfall alert\")\n",
    "    elif 1 < precip <= 50:\n",
    "        conditions.append(\"Clear weather with no chance of rainfall.\")\n",
    "    elif precip <= 1:\n",
    "        conditions.append(\"Dry conditions\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to interpret climatic conditions\n",
    "def interpret_climatic_conditions(predictions, columns):\n",
    "    conditions = []\n",
    "    predicted_values = dict(zip(columns, predictions))\n",
    "\n",
    "    # Interpret temperature (convert from Kelvin to Celsius)\n",
    "    temp = predicted_values.get(\"t2m\", 0) - 273.15  # Convert Kelvin to Celsius\n",
    "    if temp > 35:\n",
    "        conditions.append(\"Heatwave warning\")\n",
    "    elif 35 <= temp > 0:\n",
    "        conditions.append(\"Normal temperature\")\n",
    "    elif temp < 0:\n",
    "        conditions.append(\"Frost warning\")\n",
    "\n",
    "    # Interpret precipitation\n",
    "    precip = predicted_values.get(\"tp\", 0)  # Replace \"tp\" with actual precipitation column name\n",
    "    if precip > 50:\n",
    "        conditions.append(\"Heavy rainfall alert\")\n",
    "    elif 50 <= precip > 1:\n",
    "        conditions.append(\"Clear weather no chance of rainfall.\")\n",
    "    elif precip < 1:\n",
    "        conditions.append(\"Dry conditions\")\n",
    "\n",
    "    # Interpret wind\n",
    "    wind_u = predicted_values.get(\"u10\", 0)  # Replace \"u10\" with actual zonal wind column name\n",
    "    wind_v = predicted_values.get(\"v10\", 0)  # Replace \"v10\" with actual meridional wind column name\n",
    "    wind_speed = (wind_u*2 + wind_v**2)*0.5  # Correct calculation for wind speed\n",
    "    if wind_speed > 50:\n",
    "        conditions.append(\"Strong wind advisory\")\n",
    "    else: \n",
    "        conditions.append(\"Normal wind speed\")\n",
    "\n",
    "    # Interpret pressure\n",
    "    pressure = predicted_values.get(\"sp\", 0)  # Replace \"sp\" with actual pressure column name\n",
    "    if pressure < 1000:\n",
    "        conditions.append(\"Low pressure: Possible storm\")\n",
    "    else:\n",
    "        conditions.append(\"Normal pressure: No sign of storm\")\n",
    "\n",
    "    return conditions, temp  # Return conditions and temperature in Celsius"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 25ms/step\n",
      "Predicted values for 2023-05-15, 12:00:\n",
      "Temperature (Celsius): 24.51\n",
      "Dry conditions\n",
      "Normal wind speed\n",
      "Normal pressure: No sign of storm\n"
     ]
    }
   ],
   "source": [
    "# user input\n",
    "user_date = \"2023-05-15\"\n",
    "user_hour = 12\n",
    "user_prediction = predict_for_date(user_date, user_hour)\n",
    "\n",
    "# Dynamically identify target column names (assuming already loaded dataset)\n",
    "target_columns = list(processed_data.drop(columns=['day_of_year', 'hour']).columns)\n",
    "\n",
    "# Interpret the climatic conditions\n",
    "conditions, temperature_celsius = interpret_climatic_conditions(user_prediction, target_columns)\n",
    "\n",
    "# Display the results\n",
    "print(f\"Predicted values for {user_date}, {user_hour}:00:\")\n",
    "print(f\"Temperature (Celsius): {temperature_celsius:.2f}\")\n",
    "for condition in conditions:\n",
    "    print(condition)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
