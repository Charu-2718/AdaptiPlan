{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "2300/2300 [==============================] - 20s 6ms/step - loss: 0.0541 - mae: 0.1575 - val_loss: 0.0446 - val_mae: 0.1394\n",
      "Epoch 2/25\n",
      "2300/2300 [==============================] - 11s 5ms/step - loss: 0.0453 - mae: 0.1408 - val_loss: 0.0428 - val_mae: 0.1332\n",
      "Epoch 3/25\n",
      "2300/2300 [==============================] - 13s 6ms/step - loss: 0.0421 - mae: 0.1325 - val_loss: 0.0397 - val_mae: 0.1251\n",
      "Epoch 4/25\n",
      "2300/2300 [==============================] - 13s 6ms/step - loss: 0.0396 - mae: 0.1261 - val_loss: 0.0378 - val_mae: 0.1214\n",
      "Epoch 5/25\n",
      "2300/2300 [==============================] - 13s 6ms/step - loss: 0.0386 - mae: 0.1235 - val_loss: 0.0374 - val_mae: 0.1198\n",
      "Epoch 6/25\n",
      "2300/2300 [==============================] - 13s 6ms/step - loss: 0.0382 - mae: 0.1222 - val_loss: 0.0371 - val_mae: 0.1198\n",
      "Epoch 7/25\n",
      "2300/2300 [==============================] - 13s 6ms/step - loss: 0.0379 - mae: 0.1214 - val_loss: 0.0371 - val_mae: 0.1185\n",
      "Epoch 8/25\n",
      "2300/2300 [==============================] - 13s 6ms/step - loss: 0.0378 - mae: 0.1208 - val_loss: 0.0368 - val_mae: 0.1177\n",
      "Epoch 9/25\n",
      "2300/2300 [==============================] - 13s 6ms/step - loss: 0.0376 - mae: 0.1204 - val_loss: 0.0368 - val_mae: 0.1185\n",
      "Epoch 10/25\n",
      "2300/2300 [==============================] - 13s 6ms/step - loss: 0.0375 - mae: 0.1201 - val_loss: 0.0367 - val_mae: 0.1187\n",
      "Epoch 11/25\n",
      "2300/2300 [==============================] - 13s 6ms/step - loss: 0.0374 - mae: 0.1198 - val_loss: 0.0367 - val_mae: 0.1175\n",
      "Epoch 12/25\n",
      "2300/2300 [==============================] - 13s 6ms/step - loss: 0.0373 - mae: 0.1196 - val_loss: 0.0366 - val_mae: 0.1169\n",
      "Epoch 13/25\n",
      "2300/2300 [==============================] - 13s 6ms/step - loss: 0.0373 - mae: 0.1194 - val_loss: 0.0365 - val_mae: 0.1173\n",
      "Epoch 14/25\n",
      "2300/2300 [==============================] - 13s 6ms/step - loss: 0.0372 - mae: 0.1192 - val_loss: 0.0364 - val_mae: 0.1171\n",
      "Epoch 15/25\n",
      "2300/2300 [==============================] - 13s 6ms/step - loss: 0.0372 - mae: 0.1192 - val_loss: 0.0364 - val_mae: 0.1175\n",
      "Epoch 16/25\n",
      "2300/2300 [==============================] - 10s 5ms/step - loss: 0.0371 - mae: 0.1190 - val_loss: 0.0364 - val_mae: 0.1163\n",
      "Epoch 17/25\n",
      "2300/2300 [==============================] - 10s 4ms/step - loss: 0.0371 - mae: 0.1189 - val_loss: 0.0366 - val_mae: 0.1160\n",
      "Epoch 18/25\n",
      "2300/2300 [==============================] - 12s 5ms/step - loss: 0.0370 - mae: 0.1187 - val_loss: 0.0364 - val_mae: 0.1171\n",
      "Epoch 19/25\n",
      "2300/2300 [==============================] - 13s 6ms/step - loss: 0.0370 - mae: 0.1187 - val_loss: 0.0362 - val_mae: 0.1158\n",
      "Epoch 20/25\n",
      "2300/2300 [==============================] - 13s 6ms/step - loss: 0.0370 - mae: 0.1187 - val_loss: 0.0364 - val_mae: 0.1171\n",
      "Epoch 21/25\n",
      "2300/2300 [==============================] - 13s 6ms/step - loss: 0.0370 - mae: 0.1186 - val_loss: 0.0362 - val_mae: 0.1169\n",
      "Epoch 22/25\n",
      "2300/2300 [==============================] - 13s 6ms/step - loss: 0.0370 - mae: 0.1186 - val_loss: 0.0363 - val_mae: 0.1172\n",
      "Epoch 23/25\n",
      "2300/2300 [==============================] - 13s 6ms/step - loss: 0.0369 - mae: 0.1185 - val_loss: 0.0361 - val_mae: 0.1162\n",
      "Epoch 24/25\n",
      "2300/2300 [==============================] - 13s 6ms/step - loss: 0.0369 - mae: 0.1184 - val_loss: 0.0361 - val_mae: 0.1157\n",
      "Epoch 25/25\n",
      "2300/2300 [==============================] - 13s 6ms/step - loss: 0.0369 - mae: 0.1184 - val_loss: 0.0361 - val_mae: 0.1160\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Charu Gupta\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\engine\\training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "import datetime\n",
    "import joblib\n",
    "\n",
    "# Load the dataset\n",
    "dataset = pd.read_csv('new_dataset.csv')  # Replace with your dataset's path\n",
    "\n",
    "# Extract features and targets\n",
    "dataset['valid_time'] = pd.to_datetime(dataset['valid_time'])\n",
    "dataset['day_of_year'] = dataset['valid_time'].dt.dayofyear\n",
    "dataset['hour'] = dataset['valid_time'].dt.hour\n",
    "processed_data = dataset.drop(columns=['valid_time', 'number', 'expver'])\n",
    "\n",
    "X = processed_data[['day_of_year', 'hour']].values\n",
    "y = processed_data.drop(columns=['day_of_year', 'hour']).values\n",
    "\n",
    "# Normalize the input features (X) and target values (y)\n",
    "scaler_X = MinMaxScaler()\n",
    "X_scaled = scaler_X.fit_transform(X)\n",
    "\n",
    "scaler_y = MinMaxScaler()\n",
    "y_scaled = scaler_y.fit_transform(y)\n",
    "\n",
    "# Save the scalers for later use\n",
    "joblib.dump(scaler_X, \"scaler_X.pkl\")\n",
    "joblib.dump(scaler_y, \"scaler_y.pkl\")\n",
    "\n",
    "# Reshape X_scaled to a 3D array (samples, timesteps, features)\n",
    "X_scaled = np.expand_dims(X_scaled, axis=1)  # Add a timestep dimension\n",
    "\n",
    "# Split the dataset into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_scaled, y_scaled, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define the LSTM model\n",
    "model = Sequential([\n",
    "    LSTM(128, activation='relu', input_shape=(X_scaled.shape[1], X_scaled.shape[2]), return_sequences=True),\n",
    "    Dropout(0.2),\n",
    "    LSTM(64, activation='relu', return_sequences=False),\n",
    "    Dropout(0.2),\n",
    "    Dense(y_scaled.shape[1])  # Output layer matches the number of target features\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs=25,\n",
    "    batch_size=32,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Save the trained model\n",
    "model_file_path = 'lstm_model.h5'\n",
    "model.save(model_file_path)\n",
    "\n",
    "\n",
    "# Define the prediction function\n",
    "def predict_for_date(date_string, hour):\n",
    "    # Convert date string to day_of_year\n",
    "    input_date = datetime.datetime.strptime(date_string, \"%Y-%m-%d\")\n",
    "    day_of_year = input_date.timetuple().tm_yday\n",
    "    input_features = np.array([[day_of_year, hour]])  # Create a 2D array for input features\n",
    "\n",
    "    # Normalize the input features using scaler_X\n",
    "    input_features_scaled = scaler_X.transform(input_features)\n",
    "\n",
    "    # Reshape to match LSTM input shape (samples, timesteps, features)\n",
    "    input_features_scaled = np.expand_dims(input_features_scaled, axis=1)  # Add timestep dimension\n",
    "\n",
    "    # Make predictions\n",
    "    predictions_scaled = model.predict(input_features_scaled)\n",
    "\n",
    "    # Rescale predictions back to the original range using scaler_y\n",
    "    predictions_rescaled = scaler_y.inverse_transform(predictions_scaled)\n",
    "\n",
    "    return predictions_rescaled[0]  # Return as a flat array\n",
    "\n",
    "\n",
    "# Define the function to interpret climatic conditions\n",
    "def interpret_climatic_conditions(predictions, columns):\n",
    "    conditions = []\n",
    "    predicted_values = dict(zip(columns, predictions))\n",
    "\n",
    "    # Interpret temperature (convert from Kelvin to Celsius)\n",
    "    temp = predicted_values.get(\"t2m\", 0) - 273.15  # Convert Kelvin to Celsius\n",
    "    if temp > 35:\n",
    "        conditions.append(\"Heatwave warning\")\n",
    "    elif 0 <= temp <= 35:\n",
    "        conditions.append(\"Normal temperature\")\n",
    "    elif temp < 0:\n",
    "        conditions.append(\"Frost warning\")\n",
    "\n",
    "    # Interpret precipitation\n",
    "    precip = predicted_values.get(\"tp\", 0)  # Replace \"tp\" with actual precipitation column name\n",
    "    if precip > 50:\n",
    "        conditions.append(\"Heavy rainfall alert\")\n",
    "    elif 1 < precip <= 50:\n",
    "        conditions.append(\"Clear weather with no chance of rainfall.\")\n",
    "    elif precip <= 1:\n",
    "        conditions.append(\"Dry conditions\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6: Save the trained model\n",
    "model_file_path = 'lstm_model.h5'  # Update the path if necessary\n",
    "model.save(model_file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_for_date(date_string, hour):\n",
    "    # Convert date string to day_of_year\n",
    "    input_date = datetime.datetime.strptime(date_string, \"%Y-%m-%d\")\n",
    "    day_of_year = input_date.timetuple().tm_yday\n",
    "    input_features = np.array([[day_of_year, hour]])  # Create a 2D array for input features\n",
    "\n",
    "    # Normalize the input features using scaler_X\n",
    "    input_features_scaled = scaler_X.transform(input_features)\n",
    "\n",
    "    # Reshape to match LSTM input shape (samples, timesteps, features)\n",
    "    input_features_scaled = np.expand_dims(input_features_scaled, axis=1)  # Add timestep dimension\n",
    "\n",
    "    # Make predictions\n",
    "    predictions_scaled = model.predict(input_features_scaled)\n",
    "\n",
    "    # Rescale predictions back to original range using scaler_y\n",
    "    predictions_rescaled = scaler_y.inverse_transform(predictions_scaled)\n",
    "\n",
    "    return predictions_rescaled[0]  # Return as a flat array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 2s 2s/step\n",
      "\n",
      "Labeled Predictions:\n",
      "Latitude: 30.0\n",
      "Longitude: 78.25\n",
      "U10: 0.9200000166893005\n",
      "V10: -0.3499999940395355\n",
      "D2m: 290.3500061035156\n",
      "T2m: 300.1499938964844\n",
      "Sp: 88496.09375\n",
      "Tp: 0.0\n",
      "Skt: 299.4200134277344\n",
      "Ssrd: 1026420.0625\n",
      "Hcc: 0.2800000011920929\n",
      "Lcc: 0.07999999821186066\n",
      "Mcc: 0.20999999344348907\n",
      "Tcc: 0.4399999976158142\n",
      "E: -0.0\n",
      "Cp: 0.0\n",
      "Lsp: -0.0\n",
      "Ptype: 0.3700000047683716\n",
      "Sf: 0.0\n",
      "Z: 11214.669921875\n"
     ]
    }
   ],
   "source": [
    "# Dynamically identify target column names\n",
    "target_columns = list(processed_data.drop(columns=['day_of_year', 'hour']).columns)\n",
    "\n",
    "# Function to display predictions\n",
    "def display_predictions(predictions, columns):\n",
    "    # Format predictions for readability\n",
    "    formatted_predictions = [round(value, 2) for value in predictions]\n",
    "\n",
    "    # Map predictions to corresponding columns\n",
    "    predicted_values = dict(zip(columns, formatted_predictions))\n",
    "\n",
    "    # Print labeled predictions\n",
    "    print(\"\\nLabeled Predictions:\")\n",
    "    for key, value in predicted_values.items():\n",
    "        print(f\"{key.capitalize()}: {value}\")\n",
    "\n",
    "# Example prediction for a specific date and hour\n",
    "user_date = \"2023-06-15\"  # Date for prediction\n",
    "user_hour = 12  # Hour for prediction\n",
    "\n",
    "# Make the prediction\n",
    "user_prediction = predict_for_date(user_date, user_hour)\n",
    "\n",
    "# Display predictions with proper labels\n",
    "display_predictions(user_prediction, target_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to interpret climatic conditions\n",
    "def interpret_climatic_conditions(predictions, columns):\n",
    "    conditions = []\n",
    "    predicted_values = dict(zip(columns, predictions))\n",
    "\n",
    "    # Interpret temperature (convert from Kelvin to Celsius)\n",
    "    temp = predicted_values.get(\"t2m\", 0) - 273.15  # Convert Kelvin to Celsius\n",
    "    if temp > 35:\n",
    "        conditions.append(\"Heatwave warning\")\n",
    "    elif 35 <= temp > 0:\n",
    "        conditions.append(\"Normal temperature\")\n",
    "    elif temp < 0:\n",
    "        conditions.append(\"Frost warning\")\n",
    "\n",
    "    # Interpret precipitation\n",
    "    precip = predicted_values.get(\"tp\", 0)  # Replace \"tp\" with actual precipitation column name\n",
    "    if precip > 50:\n",
    "        conditions.append(\"Heavy rainfall alert\")\n",
    "    elif 50 <= precip > 1:\n",
    "        conditions.append(\"Clear weather no chance of rainfall.\")\n",
    "    elif precip < 1:\n",
    "        conditions.append(\"Dry conditions\")\n",
    "\n",
    "    # Interpret wind\n",
    "    wind_u = predicted_values.get(\"u10\", 0)  # Replace \"u10\" with actual zonal wind column name\n",
    "    wind_v = predicted_values.get(\"v10\", 0)  # Replace \"v10\" with actual meridional wind column name\n",
    "    wind_speed = (wind_u*2 + wind_v**2)*0.5  # Correct calculation for wind speed\n",
    "    if wind_speed > 50:\n",
    "        conditions.append(\"Strong wind advisory\")\n",
    "    else: \n",
    "        conditions.append(\"Normal wind speed\")\n",
    "\n",
    "    # Interpret pressure\n",
    "    pressure = predicted_values.get(\"sp\", 0)  # Replace \"sp\" with actual pressure column name\n",
    "    if pressure < 1000:\n",
    "        conditions.append(\"Low pressure: Possible storm\")\n",
    "    else:\n",
    "        conditions.append(\"Normal pressure: No sign of storm\")\n",
    "\n",
    "    return conditions, temp  # Return conditions and temperature in Celsius"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 28ms/step\n",
      "Predicted values for 2023-01-15, 12:00:\n",
      "Temperature (Celsius): 12.29\n",
      "Dry conditions\n",
      "Normal wind speed\n",
      "Normal pressure: No sign of storm\n"
     ]
    }
   ],
   "source": [
    "# Example prediction for user input\n",
    "user_date = \"2023-01-15\"\n",
    "user_hour = 12\n",
    "user_prediction = predict_for_date(user_date, user_hour)\n",
    "\n",
    "# Dynamically identify target column names (assuming already loaded dataset)\n",
    "target_columns = list(processed_data.drop(columns=['day_of_year', 'hour']).columns)\n",
    "\n",
    "# Interpret the climatic conditions\n",
    "conditions, temperature_celsius = interpret_climatic_conditions(user_prediction, target_columns)\n",
    "\n",
    "# Display the results\n",
    "print(f\"Predicted values for {user_date}, {user_hour}:00:\")\n",
    "print(f\"Temperature (Celsius): {temperature_celsius:.2f}\")\n",
    "for condition in conditions:\n",
    "    print(condition)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
